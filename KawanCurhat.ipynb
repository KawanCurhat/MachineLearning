{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR5aZi97ewie",
        "outputId": "3bb1373c-cfe6-403b-f5c6-92c07280a849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import json\n",
        "import pickle\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.optimizers import SGD\n",
        "import random\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "dTnI31eNfk71"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "data_file = open(\"intents.json\").read()\n",
        "intents = json.loads(data_file)"
      ],
      "metadata": {
        "id": "7Qk870yUgB46"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    w = nltk.word_tokenize(pattern)\n",
        "    words.extend(w)\n",
        "    documents.append((w, intent['tag']))\n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])"
      ],
      "metadata": {
        "id": "weKR7UILih0A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"~This is words list~\")\n",
        "print(words[3:5])\n",
        "print(\"-\"*50)\n",
        "print(\"~This is documents list~\")\n",
        "print(documents[3:5])\n",
        "print(\"-\"*50)\n",
        "print(\"~This is classes list~\")\n",
        "print(classes[3:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AomKlhmTj1nv",
        "outputId": "84cd8170-dbdc-4000-fea7-4cc5d5329bd1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~This is words list~\n",
            "['ada', 'orang']\n",
            "--------------------------------------------------\n",
            "~This is documents list~\n",
            "[(['Hi', 'there'], 'greetings'), (['Hello'], 'greetings')]\n",
            "--------------------------------------------------\n",
            "~This is classes list~\n",
            "['evening', 'night', 'goodbye', 'thanks', 'no-response', 'neutral-response', 'about']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print(\"~Document Length~\")\n",
        "print(len(documents), \"documents\\n\\n\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "print(\"~Class Length~\")\n",
        "print(len(classes), \"classes\\n\\n\", classes)\n",
        "print(\"-\"*100)\n",
        "\n",
        "print(\"~Word Length~\")\n",
        "print(len(words), \"unique lemmatized words\\n\\n\", words)\n",
        "\n",
        "pickle.dump(words, open('words.pkl', 'wb'))\n",
        "pickle.dump(classes, open('classes.pkl', 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiiaPqWwkVrL",
        "outputId": "2f224d66-5c00-4d55-f075-87e5382b2493"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~Document Length~\n",
            "232 documents\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "~Class Length~\n",
            "80 classes\n",
            "\n",
            " ['about', 'afternoon', 'anxious', 'ask', 'casual', 'creation', 'death', 'default', 'depressed', 'done', 'evening', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greetings', 'happy', 'hate-me', 'hate-you', 'help', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'name', 'neutral-response', 'night', 'no-approach', 'no-response', 'not-talking', 'pandora-useful', 'problem', 'repeat', 'sad', 'scared', 'skill', 'sleep', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'worthless', 'wrong']\n",
            "----------------------------------------------------------------------------------------------------\n",
            "~Word Length~\n",
            "277 unique lemmatized words\n",
            "\n",
            " [',', '.', 'a', 'ada', 'adikku', 'ahli', 'akal', 'akan', 'aku', 'alami', 'anak', 'anda', 'antara', 'apa', 'apa-apa', 'apakah', 'artinya', 'atas', 'atau', 'au', 'ayahku', 'bagaimana', 'bagi', 'bahagia', 'baik', 'baik-baik', 'bantu', 'bantuan', 'bantuannya', 'banyak', 'baru', 'beberapa', 'begitu', 'belajar', 'belum', 'benar', 'benci', 'berguna', 'berharga', 'berlatih', 'berpikir', 'bertanya', 'biasa', 'bicarakan', 'bisa', 'bisakah', 'bodoh', 'bolehkah', 'bonjour', 'bunuh', 'butuh', 'cemas', 'ceria', 'ceritakan', 'cukup', 'dalam', 'dan', 'dapat', 'dapatkah', 'definisikan', 'dekat', 'dengan', 'depresi', 'di', 'diam', 'diciptakan', 'dikatakan', 'diri', 'dirimu', 'do', 'doe', 'dukung', 'dukungan', 'dunia', 'fakta', 'fokus', 'gangguan', 'gejala', 'gila', 'guten', 'hal', 'halo', 'hanya', 'hanyalah', 'hari', 'harus', 'hello', 'hey', 'hi', 'hmmm', 'hola', 'howdy', 'hubungan', 'ibuku', 'ingin', 'ini', 'insomnia', 'is', 'istirahat', 'itu', 'jalan', 'jauh', 'jawaban', 'jenis', 'jika', 'jiwa', 'juga', 'jumpa', 'k', 'kakakku', 'kamu', 'karena', 'kasih', 'katakan', 'kau', 'kecemasan', 'kedengarannya', 'kelompok', 'keluarga', 'keluargaku', 'kendalikan', 'kesedihan', 'kesehatan', 'kesepian', 'ketahui', 'keuangan', 'kita', 'konnichiwa', 'kosong', 'kupikirkan', 'kurasa', 'lagi', 'lain', 'lakukan', 'lanjut', 'lebih', 'lelah', 'lelucon', 'lewat', 'lokasi', 'luar', 'malam', 'mana', 'mandek', 'mari', 'masalah', 'masih', 'masuk', 'mati', 'meditasi', 'melakukan', 'memanggilmu', 'membantu', 'membenciku', 'memberitahuku', 'membicarakan', 'membicarakannya', 'membuka', 'memiliki', 'mempelajarinya', 'memulai', 'mencari', 'mencegah', 'menciptakan', 'mendapatkan', 'menderita', 'menemukan', 'mengalami', 'mengapa', 'mengenal', 'mengerikan', 'mengerti', 'mengkhawatirkan', 'mengulanginya', 'meninggal', 'menjaga', 'menjauhlah', 'mental', 'menyebabkan', 'menyebutkannya', 'menyukai', 'menyukaiku', 'merasa', 'mungkin', 'nama', 'namamu', 'nasihat', 'nyenyak', 'obat', 'oh', 'ok', 'oke', 'ola', 'orang', 'pacar', 'pada', 'pagi', 'pantas', 'pendukung', 'pengobatan', 'penting', 'pentingnya', 'penyakit', 'perawatan', 'perbedaan', 'percaya', 'pergi', 'peringatan', 'perlu', 'pikir', 'pilihan', 'profesional', 'punya', 'revoir', 'robot', 'saja', 'sakit', 'salah', 'sampai', 'sana', 'sangat', 'saya', 'sayonara', 'sebelum', 'sedih', 'sehat', 'sekarang', 'selama', 'selamat', 'semakin', 'sembuh', 'sendiri', 'seperti', 'sepertinya', 'seseorang', 'sesuatu', 'siang', 'siap', 'siapa', 'siapa-siapa', 'sosial', 'stres', 'sudah', 'suka', 'tag', 'tahan', 'tahu', 'takut', 'tampaknya', 'tanda-tanda', 'teman', 'temanku', 'tentang', 'tentu', 'tepat', 'terakhir', 'terapi', 'terima', 'terkena', 'terlibat', 'tersedia', 'terserah', 'tertarik', 'terus', 'therapist', 'there', 'tidak', 'tidur', 'tinggal', 'tolong', 'uang', 'ujian', 'ujianku', 'untuk', 'what', 'ya', 'yang']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "for doc in documents:\n",
        "  bag = []\n",
        "  pattern_words = doc[0]\n",
        "  pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "\n",
        "  for w in words:\n",
        "    bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "  training.append([bag, output_row])\n",
        "\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "\n",
        "print(\"Training data created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7usgobTmJZr",
        "outputId": "21b1cc43-ac0d-46a4-ae43-a0f7aafcb874"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(258, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "adam_optimizer = Adam()\n",
        "# sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
        "model.save('chatbot.h5', hist)\n",
        "print(\"\\n\")\n",
        "print(\"*\" * 50)\n",
        "print(\"\\nModel Created Successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJKpSSpmnQfk",
        "outputId": "98b26008-ef13-4242-a6c8-2b03e6034266"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 1s 3ms/step - loss: 4.3916 - accuracy: 0.0302\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 4.2487 - accuracy: 0.0948\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 4.1397 - accuracy: 0.0819\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 3.9775 - accuracy: 0.0948\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 3.7818 - accuracy: 0.1466\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 3.5775 - accuracy: 0.1767\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 3.4422 - accuracy: 0.2155\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 3.2179 - accuracy: 0.2845\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 2.9543 - accuracy: 0.3190\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.7880 - accuracy: 0.3190\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 2.4936 - accuracy: 0.3966\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.4755 - accuracy: 0.3578\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.2494 - accuracy: 0.4784\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.1016 - accuracy: 0.4871\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.0215 - accuracy: 0.5043\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.7670 - accuracy: 0.5388\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 8ms/step - loss: 1.7221 - accuracy: 0.5862\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 7ms/step - loss: 1.6387 - accuracy: 0.5733\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 6ms/step - loss: 1.4625 - accuracy: 0.6509\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.2911 - accuracy: 0.6509\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.2656 - accuracy: 0.6509\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.1709 - accuracy: 0.7284\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.2455 - accuracy: 0.6681\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.0700 - accuracy: 0.7500\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.7198\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.7414\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.8997 - accuracy: 0.7716\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.8608 - accuracy: 0.7457\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.8758 - accuracy: 0.7543\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.8260 - accuracy: 0.7845\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.8577 - accuracy: 0.7629\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.7659 - accuracy: 0.8060\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.8362\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.7974\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.8319\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.6116 - accuracy: 0.8534\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.8319\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.8319\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.8664\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.8578\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.8578\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.5733 - accuracy: 0.8276\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.8879\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.8793\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.8664\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.8879\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8879\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.9138\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8966\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8664\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3258 - accuracy: 0.9224\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.9138\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.9267\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8836\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.2991 - accuracy: 0.9224\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.9138\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.9138\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3170 - accuracy: 0.9181\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3263 - accuracy: 0.8966\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2874 - accuracy: 0.9052\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.9181\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.9224\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8879\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.9095\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.9009\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.9224\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3162 - accuracy: 0.9052\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9440\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.9224\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9569\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.9440\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.9224\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2231 - accuracy: 0.9310\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9569\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9224\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2381 - accuracy: 0.9483\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9397\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9397\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9526\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9397\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9310\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9353\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9353\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9267\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9569\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9828\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9353\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2203 - accuracy: 0.9310\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9440\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9353\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9612\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1646 - accuracy: 0.9526\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9353\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1342 - accuracy: 0.9698\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9569\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9440\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9483\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1669 - accuracy: 0.9526\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9224\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9655\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9353\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9483\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1692 - accuracy: 0.9353\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9569\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9612\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9483\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9310\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9526\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9655\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9655\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9655\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9526\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1614 - accuracy: 0.9526\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2226 - accuracy: 0.9138\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1292 - accuracy: 0.9612\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9655\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9569\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1557 - accuracy: 0.9483\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9397\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9612\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9698\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9655\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9655\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9784\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9655\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9569\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9569\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1035 - accuracy: 0.9741\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9397\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 0.9397\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9828\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9612\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9784\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9655\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9440\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9741\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1353 - accuracy: 0.9526\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.0954 - accuracy: 0.9784\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9569\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9440\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9397\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.0954 - accuracy: 0.9741\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9741\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9655\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9698\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9741\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9526\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9655\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9784\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9741\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1144 - accuracy: 0.9612\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.9353\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9569\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9569\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1314 - accuracy: 0.9741\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9698\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9655\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1264 - accuracy: 0.9655\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1171 - accuracy: 0.9612\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1128 - accuracy: 0.9741\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9612\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9698\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1540 - accuracy: 0.9397\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.9698\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1127 - accuracy: 0.9655\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9569\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9483\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9440\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9741\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9741\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.9612\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9655\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9698\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1014 - accuracy: 0.9612\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9612\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0997 - accuracy: 0.9698\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9397\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9741\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0995 - accuracy: 0.9698\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9698\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9569\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9698\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0937 - accuracy: 0.9698\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0828 - accuracy: 0.9741\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0776 - accuracy: 0.9828\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9569\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9655\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9698\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9569\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9741\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9612\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9698\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1141 - accuracy: 0.9612\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9698\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0998 - accuracy: 0.9784\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9655\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9698\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9569\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9698\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9698\n",
            "\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Model Created Successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAof1vJGpJjF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}