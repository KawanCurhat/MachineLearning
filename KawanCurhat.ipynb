{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FR5aZi97ewie",
        "outputId": "3060dae7-e88e-41c1-c330-c8711d7a2c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import json\n",
        "import pickle\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.optimizers import SGD\n",
        "import random\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "dTnI31eNfk71"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "data_file = open(\"intents.json\").read()\n",
        "intents = json.loads(data_file)"
      ],
      "metadata": {
        "id": "7Qk870yUgB46"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    w = nltk.word_tokenize(pattern)\n",
        "    words.extend(w)\n",
        "    documents.append((w, intent['tag']))\n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])"
      ],
      "metadata": {
        "id": "weKR7UILih0A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"~This is words list~\")\n",
        "print(words[3:5])\n",
        "print(\"-\"*50)\n",
        "print(\"~This is documents list~\")\n",
        "print(documents[3:5])\n",
        "print(\"-\"*50)\n",
        "print(\"~This is classes list~\")\n",
        "print(classes[3:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AomKlhmTj1nv",
        "outputId": "4678126f-7ca4-4949-da77-ad9be518fe34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~This is words list~\n",
            "['ada', 'orang']\n",
            "--------------------------------------------------\n",
            "~This is documents list~\n",
            "[(['Hi', 'there'], 'greetings'), (['Hello'], 'greetings')]\n",
            "--------------------------------------------------\n",
            "~This is classes list~\n",
            "['evening', 'night', 'goodbye', 'thanks', 'no-response', 'neutral-response', 'about']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print(\"~Document Length~\")\n",
        "print(len(documents), \"documents\\n\\n\")\n",
        "print(\"-\"*100)\n",
        "\n",
        "print(\"~Class Length~\")\n",
        "print(len(classes), \"classes\\n\\n\", classes)\n",
        "print(\"-\"*100)\n",
        "\n",
        "print(\"~Word Length~\")\n",
        "print(len(words), \"unique lemmatized words\\n\\n\", words)\n",
        "\n",
        "pickle.dump(words, open('words.pkl', 'wb'))\n",
        "pickle.dump(classes, open('classes.pkl', 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiiaPqWwkVrL",
        "outputId": "818c4b1a-fbd7-408b-b38d-efaa561ded88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~Document Length~\n",
            "232 documents\n",
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "~Class Length~\n",
            "80 classes\n",
            "\n",
            " ['about', 'afternoon', 'anxious', 'ask', 'casual', 'creation', 'death', 'default', 'depressed', 'done', 'evening', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greetings', 'happy', 'hate-me', 'hate-you', 'help', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'name', 'neutral-response', 'night', 'no-approach', 'no-response', 'not-talking', 'pandora-useful', 'problem', 'repeat', 'sad', 'scared', 'skill', 'sleep', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'worthless', 'wrong']\n",
            "----------------------------------------------------------------------------------------------------\n",
            "~Word Length~\n",
            "277 unique lemmatized words\n",
            "\n",
            " [',', '.', 'a', 'ada', 'adikku', 'ahli', 'akal', 'akan', 'aku', 'alami', 'anak', 'anda', 'antara', 'apa', 'apa-apa', 'apakah', 'artinya', 'atas', 'atau', 'au', 'ayahku', 'bagaimana', 'bagi', 'bahagia', 'baik', 'baik-baik', 'bantu', 'bantuan', 'bantuannya', 'banyak', 'baru', 'beberapa', 'begitu', 'belajar', 'belum', 'benar', 'benci', 'berguna', 'berharga', 'berlatih', 'berpikir', 'bertanya', 'biasa', 'bicarakan', 'bisa', 'bisakah', 'bodoh', 'bolehkah', 'bonjour', 'bunuh', 'butuh', 'cemas', 'ceria', 'ceritakan', 'cukup', 'dalam', 'dan', 'dapat', 'dapatkah', 'definisikan', 'dekat', 'dengan', 'depresi', 'di', 'diam', 'diciptakan', 'dikatakan', 'diri', 'dirimu', 'do', 'doe', 'dukung', 'dukungan', 'dunia', 'fakta', 'fokus', 'gangguan', 'gejala', 'gila', 'guten', 'hal', 'halo', 'hanya', 'hanyalah', 'hari', 'harus', 'hello', 'hey', 'hi', 'hmmm', 'hola', 'howdy', 'hubungan', 'ibuku', 'ingin', 'ini', 'insomnia', 'is', 'istirahat', 'itu', 'jalan', 'jauh', 'jawaban', 'jenis', 'jika', 'jiwa', 'juga', 'jumpa', 'k', 'kakakku', 'kamu', 'karena', 'kasih', 'katakan', 'kau', 'kecemasan', 'kedengarannya', 'kelompok', 'keluarga', 'keluargaku', 'kendalikan', 'kesedihan', 'kesehatan', 'kesepian', 'ketahui', 'keuangan', 'kita', 'konnichiwa', 'kosong', 'kupikirkan', 'kurasa', 'lagi', 'lain', 'lakukan', 'lanjut', 'lebih', 'lelah', 'lelucon', 'lewat', 'lokasi', 'luar', 'malam', 'mana', 'mandek', 'mari', 'masalah', 'masih', 'masuk', 'mati', 'meditasi', 'melakukan', 'memanggilmu', 'membantu', 'membenciku', 'memberitahuku', 'membicarakan', 'membicarakannya', 'membuka', 'memiliki', 'mempelajarinya', 'memulai', 'mencari', 'mencegah', 'menciptakan', 'mendapatkan', 'menderita', 'menemukan', 'mengalami', 'mengapa', 'mengenal', 'mengerikan', 'mengerti', 'mengkhawatirkan', 'mengulanginya', 'meninggal', 'menjaga', 'menjauhlah', 'mental', 'menyebabkan', 'menyebutkannya', 'menyukai', 'menyukaiku', 'merasa', 'mungkin', 'nama', 'namamu', 'nasihat', 'nyenyak', 'obat', 'oh', 'ok', 'oke', 'ola', 'orang', 'pacar', 'pada', 'pagi', 'pantas', 'pendukung', 'pengobatan', 'penting', 'pentingnya', 'penyakit', 'perawatan', 'perbedaan', 'percaya', 'pergi', 'peringatan', 'perlu', 'pikir', 'pilihan', 'profesional', 'punya', 'revoir', 'robot', 'saja', 'sakit', 'salah', 'sampai', 'sana', 'sangat', 'saya', 'sayonara', 'sebelum', 'sedih', 'sehat', 'sekarang', 'selama', 'selamat', 'semakin', 'sembuh', 'sendiri', 'seperti', 'sepertinya', 'seseorang', 'sesuatu', 'siang', 'siap', 'siapa', 'siapa-siapa', 'sosial', 'stres', 'sudah', 'suka', 'tag', 'tahan', 'tahu', 'takut', 'tampaknya', 'tanda-tanda', 'teman', 'temanku', 'tentang', 'tentu', 'tepat', 'terakhir', 'terapi', 'terima', 'terkena', 'terlibat', 'tersedia', 'terserah', 'tertarik', 'terus', 'therapist', 'there', 'tidak', 'tidur', 'tinggal', 'tolong', 'uang', 'ujian', 'ujianku', 'untuk', 'what', 'ya', 'yang']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "for doc in documents:\n",
        "  bag = []\n",
        "  pattern_words = doc[0]\n",
        "  pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "\n",
        "  for w in words:\n",
        "    bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "  training.append([bag, output_row])\n",
        "\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "\n",
        "print(\"Training data created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7usgobTmJZr",
        "outputId": "90da2e53-604f-42e2-8bf1-5486c9965f99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(258, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "adam_optimizer = Adam()\n",
        "# sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
        "model.save('chatbot.h5', hist)\n",
        "print(\"\\n\")\n",
        "print(\"*\" * 50)\n",
        "print(\"\\nModel Created Successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJKpSSpmnQfk",
        "outputId": "a940229d-9fe6-4392-87b7-f2174dac6efd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "47/47 [==============================] - 1s 3ms/step - loss: 4.3902 - accuracy: 0.0259\n",
            "Epoch 2/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 4.2875 - accuracy: 0.0216\n",
            "Epoch 3/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 4.1422 - accuracy: 0.0905\n",
            "Epoch 4/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 3.9769 - accuracy: 0.0948\n",
            "Epoch 5/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 3.7929 - accuracy: 0.1422\n",
            "Epoch 6/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 3.5458 - accuracy: 0.2500\n",
            "Epoch 7/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 3.3879 - accuracy: 0.2241\n",
            "Epoch 8/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 3.1451 - accuracy: 0.2672\n",
            "Epoch 9/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.9836 - accuracy: 0.3233\n",
            "Epoch 10/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.6633 - accuracy: 0.3793\n",
            "Epoch 11/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.5799 - accuracy: 0.3578\n",
            "Epoch 12/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 2.3211 - accuracy: 0.4353\n",
            "Epoch 13/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 2.2341 - accuracy: 0.4655\n",
            "Epoch 14/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 1.9478 - accuracy: 0.5517\n",
            "Epoch 15/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 1.7933 - accuracy: 0.5560\n",
            "Epoch 16/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 1.7507 - accuracy: 0.5603\n",
            "Epoch 17/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.6554 - accuracy: 0.5733\n",
            "Epoch 18/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.5350 - accuracy: 0.6293\n",
            "Epoch 19/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.5233 - accuracy: 0.6034\n",
            "Epoch 20/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 1.3188 - accuracy: 0.6552\n",
            "Epoch 21/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 1.2924 - accuracy: 0.6724\n",
            "Epoch 22/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.2650 - accuracy: 0.6983\n",
            "Epoch 23/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 1.1810 - accuracy: 0.7069\n",
            "Epoch 24/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.0858 - accuracy: 0.7155\n",
            "Epoch 25/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 1.0319 - accuracy: 0.7457\n",
            "Epoch 26/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.9301 - accuracy: 0.7586\n",
            "Epoch 27/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.8546 - accuracy: 0.7845\n",
            "Epoch 28/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.8421 - accuracy: 0.7931\n",
            "Epoch 29/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.8248 - accuracy: 0.7974\n",
            "Epoch 30/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.7397 - accuracy: 0.8362\n",
            "Epoch 31/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.8491\n",
            "Epoch 32/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.8491\n",
            "Epoch 33/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.5697 - accuracy: 0.8621\n",
            "Epoch 34/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.8448\n",
            "Epoch 35/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.6976 - accuracy: 0.7888\n",
            "Epoch 36/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.5980 - accuracy: 0.8534\n",
            "Epoch 37/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.8578\n",
            "Epoch 38/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.8362\n",
            "Epoch 39/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.8793\n",
            "Epoch 40/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.8578\n",
            "Epoch 41/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8707\n",
            "Epoch 42/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8922\n",
            "Epoch 43/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.9181\n",
            "Epoch 44/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8664\n",
            "Epoch 45/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8966\n",
            "Epoch 46/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.8750\n",
            "Epoch 47/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8707\n",
            "Epoch 48/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8707\n",
            "Epoch 49/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.9009\n",
            "Epoch 50/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.9181\n",
            "Epoch 51/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.9009\n",
            "Epoch 52/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8922\n",
            "Epoch 53/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8922\n",
            "Epoch 54/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.9138\n",
            "Epoch 55/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.9009\n",
            "Epoch 56/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.9052\n",
            "Epoch 57/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8836\n",
            "Epoch 58/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.9181\n",
            "Epoch 59/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.9267\n",
            "Epoch 60/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.9009\n",
            "Epoch 61/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.9310\n",
            "Epoch 62/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8707\n",
            "Epoch 63/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.9310\n",
            "Epoch 64/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.9095\n",
            "Epoch 65/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.9181\n",
            "Epoch 66/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3247 - accuracy: 0.9009\n",
            "Epoch 67/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.9181\n",
            "Epoch 68/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.9310\n",
            "Epoch 69/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9483\n",
            "Epoch 70/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.9138\n",
            "Epoch 71/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.9095\n",
            "Epoch 72/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2424 - accuracy: 0.9267\n",
            "Epoch 73/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2641 - accuracy: 0.9138\n",
            "Epoch 74/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9440\n",
            "Epoch 75/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2485 - accuracy: 0.9224\n",
            "Epoch 76/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.9224\n",
            "Epoch 77/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9310\n",
            "Epoch 78/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2380 - accuracy: 0.9397\n",
            "Epoch 79/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9612\n",
            "Epoch 80/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2261 - accuracy: 0.9353\n",
            "Epoch 81/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9310\n",
            "Epoch 82/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9440\n",
            "Epoch 83/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9526\n",
            "Epoch 84/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9483\n",
            "Epoch 85/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9698\n",
            "Epoch 86/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9397\n",
            "Epoch 87/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2033 - accuracy: 0.9397\n",
            "Epoch 88/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9483\n",
            "Epoch 89/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9397\n",
            "Epoch 90/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9569\n",
            "Epoch 91/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9698\n",
            "Epoch 92/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.9267\n",
            "Epoch 93/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1586 - accuracy: 0.9483\n",
            "Epoch 94/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9612\n",
            "Epoch 95/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9569\n",
            "Epoch 96/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2399 - accuracy: 0.9224\n",
            "Epoch 97/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9310\n",
            "Epoch 98/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9440\n",
            "Epoch 99/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1848 - accuracy: 0.9655\n",
            "Epoch 100/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9483\n",
            "Epoch 101/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9569\n",
            "Epoch 102/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9397\n",
            "Epoch 103/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9483\n",
            "Epoch 104/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9138\n",
            "Epoch 105/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9397\n",
            "Epoch 106/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9483\n",
            "Epoch 107/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9741\n",
            "Epoch 108/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1155 - accuracy: 0.9655\n",
            "Epoch 109/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.9612\n",
            "Epoch 110/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9310\n",
            "Epoch 111/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9612\n",
            "Epoch 112/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9612\n",
            "Epoch 113/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1466 - accuracy: 0.9526\n",
            "Epoch 114/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9483\n",
            "Epoch 115/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9440\n",
            "Epoch 116/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9440\n",
            "Epoch 117/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9440\n",
            "Epoch 118/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9569\n",
            "Epoch 119/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9440\n",
            "Epoch 120/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9569\n",
            "Epoch 121/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1321 - accuracy: 0.9698\n",
            "Epoch 122/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1419 - accuracy: 0.9569\n",
            "Epoch 123/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9612\n",
            "Epoch 124/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9440\n",
            "Epoch 125/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1459 - accuracy: 0.9526\n",
            "Epoch 126/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9698\n",
            "Epoch 127/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9698\n",
            "Epoch 128/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9741\n",
            "Epoch 129/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1682 - accuracy: 0.9526\n",
            "Epoch 130/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9569\n",
            "Epoch 131/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9440\n",
            "Epoch 132/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9655\n",
            "Epoch 133/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9698\n",
            "Epoch 134/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9655\n",
            "Epoch 135/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9569\n",
            "Epoch 136/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9526\n",
            "Epoch 137/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 0.9784\n",
            "Epoch 138/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9569\n",
            "Epoch 139/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9698\n",
            "Epoch 140/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.9526\n",
            "Epoch 141/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9612\n",
            "Epoch 142/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9698\n",
            "Epoch 143/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9655\n",
            "Epoch 144/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1411 - accuracy: 0.9612\n",
            "Epoch 145/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9698\n",
            "Epoch 146/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9655\n",
            "Epoch 147/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1062 - accuracy: 0.9655\n",
            "Epoch 148/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1357 - accuracy: 0.9569\n",
            "Epoch 149/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.9483\n",
            "Epoch 150/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1088 - accuracy: 0.9741\n",
            "Epoch 151/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1557 - accuracy: 0.9483\n",
            "Epoch 152/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1095 - accuracy: 0.9698\n",
            "Epoch 153/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.1647 - accuracy: 0.9440\n",
            "Epoch 154/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9526\n",
            "Epoch 155/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.9310\n",
            "Epoch 156/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.9569\n",
            "Epoch 157/200\n",
            "47/47 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9741\n",
            "Epoch 158/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1430 - accuracy: 0.9526\n",
            "Epoch 159/200\n",
            "47/47 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9310\n",
            "Epoch 160/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9569\n",
            "Epoch 161/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1654 - accuracy: 0.9483\n",
            "Epoch 162/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1001 - accuracy: 0.9698\n",
            "Epoch 163/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9569\n",
            "Epoch 164/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9526\n",
            "Epoch 165/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9655\n",
            "Epoch 166/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9828\n",
            "Epoch 167/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9741\n",
            "Epoch 168/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9440\n",
            "Epoch 169/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1527 - accuracy: 0.9698\n",
            "Epoch 170/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9655\n",
            "Epoch 171/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1035 - accuracy: 0.9698\n",
            "Epoch 172/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9698\n",
            "Epoch 173/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9741\n",
            "Epoch 174/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9655\n",
            "Epoch 175/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9784\n",
            "Epoch 176/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9483\n",
            "Epoch 177/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9526\n",
            "Epoch 178/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9741\n",
            "Epoch 179/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9569\n",
            "Epoch 180/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9612\n",
            "Epoch 181/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9655\n",
            "Epoch 182/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9741\n",
            "Epoch 183/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9569\n",
            "Epoch 184/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9741\n",
            "Epoch 185/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9741\n",
            "Epoch 186/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9612\n",
            "Epoch 187/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9828\n",
            "Epoch 188/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9741\n",
            "Epoch 189/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9698\n",
            "Epoch 190/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9526\n",
            "Epoch 191/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0911 - accuracy: 0.9698\n",
            "Epoch 192/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.9741\n",
            "Epoch 193/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9655\n",
            "Epoch 194/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9828\n",
            "Epoch 195/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9569\n",
            "Epoch 196/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0796 - accuracy: 0.9741\n",
            "Epoch 197/200\n",
            "47/47 [==============================] - 0s 3ms/step - loss: 0.0947 - accuracy: 0.9569\n",
            "Epoch 198/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9569\n",
            "Epoch 199/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9828\n",
            "Epoch 200/200\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9871\n",
            "\n",
            "\n",
            "**************************************************\n",
            "\n",
            "Model Created Successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('chatbot.h5')\n",
        "intents = json.loads(open(\"intents.json\").read())\n",
        "words = pickle.load(open('words.pkl','rb'))\n",
        "classes = pickle.load(open('classes.pkl','rb'))"
      ],
      "metadata": {
        "id": "JYQ8z2UyUtlb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "  return sentence_words"
      ],
      "metadata": {
        "id": "MAof1vJGpJjF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bow(sentence, words, show_details=True):\n",
        "  sentence_words = clean_up_sentence(sentence)\n",
        "  bag = [0]*len(words)\n",
        "  for s in sentence_words:\n",
        "    for i, w in enumerate(words):\n",
        "      if w == s:\n",
        "        bag[i] = 1\n",
        "        if show_details:\n",
        "          print(\"found in bag: %s\" %w)\n",
        "  return(np.array(bag))"
      ],
      "metadata": {
        "id": "sgVX53roKA7G"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_class(sentence, model):\n",
        "  p = bow(sentence, words, show_details=False)\n",
        "  res = model.predict(np.array([p]))[0]\n",
        "  error = 0.25\n",
        "  results = [[i, r] for i, r in enumerate(res) if r>error]\n",
        "\n",
        "  results.sort(key=lambda x:[1], reverse=True)\n",
        "  return_list= []\n",
        "\n",
        "  for r in results:\n",
        "    return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "  return return_list"
      ],
      "metadata": {
        "id": "qszkeFIcLDLs"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getResponse(ints, intents_json):\n",
        "  tag = ints[0]['intent']\n",
        "  list_of_intents = intents_json['intents']\n",
        "  for i in list_of_intents:\n",
        "    if(i['tag']== tag):\n",
        "      result = random.choice(i['responses'])\n",
        "      break\n",
        "  return result\n",
        "\n",
        "def chatbot_response(text):\n",
        "  ints = predict_class(text, model)\n",
        "  res = getResponse(ints, intents)\n",
        "  return res"
      ],
      "metadata": {
        "id": "HVQDyJNzL4kt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_chat():\n",
        "  print(\"Bot: This is Jarvis! Yout Personal Assistant.\\n\\n\")\n",
        "  while True:\n",
        "    inp = str(input()).lower()\n",
        "    if inp.lower()==\"end\":\n",
        "      break\n",
        "    if inp.lower()== '' or inp.lower()== '*':\n",
        "      print('Please re-phrase your query!')\n",
        "      print(\"-\"*50)\n",
        "    else:\n",
        "      print(f\"Bot: {chatbot_response(inp)}\"+'\\n')\n",
        "      print(\"-\"*50)"
      ],
      "metadata": {
        "id": "xSZ3pT3LMf7H"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "nePtg9TeNnTY",
        "outputId": "47dcdf7f-5e69-4d0f-e724-80c4cfe5fd2e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: This is Jarvis! Yout Personal Assistant.\n",
            "\n",
            "\n",
            "Halo\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Halo. Senang melihatmu kembali. Apa yang terjadi di duniamu saat ini?\n",
            "\n",
            "--------------------------------------------------\n",
            "aku sedang capai\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Maafkan saya jika saya melakukan sesuatu yang menyinggung Anda. Saya hanya ingin membantu\n",
            "\n",
            "--------------------------------------------------\n",
            "aku capek\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Maafkan saya jika saya melakukan sesuatu yang menyinggung Anda. Saya hanya ingin membantu\n",
            "\n",
            "--------------------------------------------------\n",
            "bisakah bantu sayaa\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Bot: Ya, tentu. Bagaimana saya bisa membantu Anda?\n",
            "\n",
            "--------------------------------------------------\n",
            "saya merasa depresi\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Bot: Bicaralah padaku. Ceritakan lebih banyak. Ini membantu jika kamu membuka diri kepada orang lain.\n",
            "\n",
            "--------------------------------------------------\n",
            "jadi, saya di kuliah di bully sama teman saya. saya tidak tau harus apa. saya merasa tertindas\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Bot: Aku mengerti perasaanmu. Jangan merendahkan dirimu karena dia.\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-2e699ba20634>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-686f9099b1c4>\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bot: This is Jarvis! Yout Personal Assistant.\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}